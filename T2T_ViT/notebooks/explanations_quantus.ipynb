{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74cd7e12-613c-445d-af1a-a20a7f2a43d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3075/1069213176.py:8: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "while os.path.basename(os.getcwd()) != \"T2T_ViT\":\n",
    "    os.chdir('..')\n",
    "\n",
    "from vit_shapley.modules.surrogate import Surrogate\n",
    "from vit_shapley.modules.explainer import Explainer\n",
    "from vit_shapley.modules.explainer_utils import remake_masks, quick_test_masked\n",
    "from vit_shapley.CIFAR_10_Dataset import CIFAR_10_Dataset, CIFAR_10_Datamodule, PROJECT_ROOT, apply_masks_to_batch\n",
    "from utils import load_transferred_model\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    torch.cuda.set_device(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0125732f-0253-4647-9508-e2caf043be53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm).\n",
      "\u0000"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224]) torch.Size([32]) torch.Size([32, 1, 196])\n"
     ]
    }
   ],
   "source": [
    "datamodule = CIFAR_10_Datamodule(num_players=196, num_mask_samples=1, paired_mask_samples=False)\n",
    "datamodule.setup()\n",
    "data = next(iter(datamodule.train_dataloader()))\n",
    "\n",
    "images = data['images']\n",
    "labels = data['labels']\n",
    "masks = data['masks']\n",
    "print(images.shape, labels.shape, masks.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64fd577-9e9e-4026-8c81-8390086ed3fb",
   "metadata": {},
   "source": [
    "# Loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "773e5562-555a-4979-96f1-47b7d7e51754",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adopt performer encoder for tokens-to-token\n"
     ]
    }
   ],
   "source": [
    "surrogate_dir = PROJECT_ROOT / \"saved_models/surrogate/cifar10\"\n",
    "surrogate = Surrogate.load_from_checkpoint(\n",
    "    surrogate_dir / \"v2/player196/t2t_vit.ckpt\",\n",
    "    # surrogate_dir / \"_player16_lr1e-05_wd0.0_b256_epoch28.ckpt\",\n",
    "    map_location=\"cuda\",\n",
    "    strict=False,    # It's OK to ignore \"target_model.*\" being saved checkpoint but not in Surrogate for evaluation.\n",
    "    backbone_name=\"t2t_vit\"  # Needs to be specified for older checkpoints.\n",
    ")\n",
    "surrogate.eval()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f98a05d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adopt performer encoder for tokens-to-token\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/main/lib/python3.11/site-packages/pytorch_lightning/core/saving.py:173: Found keys that are in the model state dict but not in the checkpoint: ['head.weight', 'head.bias']\n"
     ]
    }
   ],
   "source": [
    "explainer_dir = PROJECT_ROOT / \"saved_models/explainer/cifar10/\"\n",
    "explainer = Explainer.load_from_checkpoint(\n",
    "    explainer_dir / 'v2/player196/t2t_vit.ckpt',\n",
    "    map_location=\"cuda\",\n",
    "    surrogate=deepcopy(surrogate),\n",
    "    strict=False,\n",
    "    backbone_name=\"t2t_vit\",  # Needs to be specified for older checkpoints.\n",
    "    use_convolution=False,\n",
    "    num_players=196,\n",
    ")\n",
    "explainer.eval()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7100696f-ad1c-4a01-afd0-9d8857e08462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explainer wrapper for quantus\n",
    "def shap_explain_func(model, inputs, targets, method=\"Shap\"):\n",
    "    inputs = torch.tensor(inputs)\n",
    "    targets = torch.tensor(targets)\n",
    "    with torch.no_grad():\n",
    "        shap_values_ = explainer(inputs.to(explainer.device)).cpu()  # (batch=32, num_players=196, num_classes=10)\n",
    "    shap_values = shap_values_[torch.arange(shap_values_.shape[0]), :, targets] # (batch, num_players)\n",
    "\n",
    "    shap_values_quantus = shap_values.view(32, 14, 14).repeat_interleave(16, dim=1).repeat_interleave(16, dim=2).unsqueeze(1)\n",
    "    return shap_values_quantus.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca8ae8d-3f2a-40aa-8f05-38b2e64b7e91",
   "metadata": {},
   "source": [
    "## Quantus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8c24d8e8-8923-42cd-aa75-90fcc958d15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Faithfulness correlation iteratively replaces a random subset of given attributions \n",
    "# with a baseline value and then measuring the correlation between the sum of this attribution\n",
    "# subset and the difference in function output \n",
    "\n",
    "def compute_faithfulness_correlation(explain_function, method):\n",
    "    faithfulness_correlation = quantus.FaithfulnessCorrelation(\n",
    "        nr_runs=100,  \n",
    "        subset_size=224,  \n",
    "        perturb_baseline=\"black\",\n",
    "        perturb_func=quantus.perturb_func.baseline_replacement_by_indices,\n",
    "        similarity_func=quantus.similarity_func.correlation_pearson,  \n",
    "        abs=False,  \n",
    "        return_aggregate=False,\n",
    "    )(model=surrogate.cpu(), \n",
    "      x_batch=images.numpy(),\n",
    "      y_batch=labels.numpy(),\n",
    "      explain_func=explain_function,\n",
    "      explain_func_kwargs={\"method\": method})\n",
    "\n",
    "explain_functions = [quantus.explain, quantus.explain, shap_explain_func]\n",
    "methods = [\"Saliency\", \"IntegratedGradients\", \"Shap\"]\n",
    "\n",
    "faithfulness_correlations = {}\n",
    "for explain_function, method in zip(explain_functions, methods):\n",
    "    faithfulness_correlations[method] = compute_faithfulness_correlation(explain_function, method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d2d62d5f-2709-4c67-a972-e15965f8a9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max-Sensitivity: measures the maximum sensitivity of an explanation \n",
    "# using a Monte Carlo sampling-based approximation\n",
    "\n",
    "def compute_max_sensitivity(explain_func, method):\n",
    "    max_sensitivity = quantus.MaxSensitivity(\n",
    "        nr_samples=10,\n",
    "        lower_bound=0.2\n",
    "    )(model=surrogate.cpu(), \n",
    "      x_batch=images.numpy(),\n",
    "      y_batch=labels.numpy(),\n",
    "      explain_func=explain_func,\n",
    "      explain_func_kwargs={\"method\": method})\n",
    "\n",
    "explain_functions = [quantus.explain, quantus.explain, shap_explain_func]\n",
    "methods = [\"Saliency\", \"IntegratedGradients\", \"Shap\"]\n",
    "\n",
    "max_sensitivities = {}\n",
    "for explain_function, method in zip(explain_functions, methods):\n",
    "    max_sensitivities[method] = compute_max_sensitivity(explain_function, method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7494c239-02a2-43ed-9e82-1cbf081a755a",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d6cfbb-81b3-4580-86c6-66e1150bcc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(arr) -> np.ndarray:\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    if isinstance(arr, torch.Tensor):\n",
    "        arr_copy = arr.clone().cpu().numpy()\n",
    "    else:\n",
    "        arr_copy = arr.copy()\n",
    "\n",
    "    arr_copy = quantus.normalise_func.denormalise(arr_copy, mean=mean, std=std)\n",
    "    arr_copy  = np.moveaxis(arr_copy, 0, -1)\n",
    "    arr_copy = (arr_copy * 255.).astype(np.uint8)\n",
    "    return arr_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25422e3f-2d74-4041-8013-6833025623a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "index = random.randint(0, len(images)-1)\n",
    "\n",
    "# Plot examplary explanations!\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(8, 5))\n",
    "axes[0].imshow(normalize_image(images[index].detach()), vmin=0.0, vmax=1.0)\n",
    "axes[0].title.set_text(f\"CIFAR10 {labels[index].item()}\")\n",
    "exp = axes[1].imshow(a_batch_saliency[index].reshape(224, 224), cmap=\"seismic\")\n",
    "fig.colorbar(exp, fraction=0.03, pad=0.05); \n",
    "axes[0].axis(\"off\"); axes[1].axis(\"off\"); plt.show();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
